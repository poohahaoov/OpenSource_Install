#!/bin/bash
#### openmpi-4.1.0 install ####

#---------------------------------------------------------------------------------------------------------------------

#advance preparatiogcc
#openmpi-4.1.0

#---------------------------------------------------------------------------------------------------------------------

#openmpi-4.1.0
yum install numactl-devel
yum install binutils-devel

./configure --prefix=/apps/mpi/gcc/openmpi-4.1.0 --with-lsf  \
--enable-orterun-prefix-by-default \
--enable-mpi-cxx --enable-mpi-fortran  \
--with-verbs --with-verbs-libdir=/usr/lib64 --enable-dlopen \
--with-gnu-ld LIB=-l/usr/lib64 --with-ucx=/apps/mpi/gcc/openmpi-4.1.0/ucx-1.10.0 | tee configure_result

make all -j 32 2>&1 | tee make_result
make check -j 32 2>&1 | tee make_check.result
make install

Open MPI configuration:
-----------------------
Version: 4.1.0
Build MPI C bindings: yes
Build MPI C++ bindings (deprecated): yes
Build MPI Fortran bindings: mpif.h, use mpi, use mpi_f08
MPI Build Java bindings (experimental): no
Build Open SHMEM support: yes
Debug build: no
Platform file: (none)

Miscellaneous
-----------------------
CUDA support: no
HWLOC support: internal
Libevent support: internal
PMIx support: Internal

Transports
-----------------------
Cisco usNIC: no
Cray uGNI (Gemini/Aries): no
Intel Omnipath (PSM2): no
Intel TrueScale (PSM): no
Mellanox MXM: no
Open UCX: yes
OpenFabrics OFI Libfabric: no
OpenFabrics Verbs: yes
Portals4: no
Shared memory/copy in+copy out: yes
Shared memory/Linux CMA: yes
Shared memory/Linux KNEM: no
Shared memory/XPMEM: no
TCP: yes

Resource Managers
-----------------------
Cray Alps: no
Grid Engine: no
LSF: yes
Moab: no
Slurm: yes
ssh/rsh: yes
Torque: no

OMPIO File Systems
-----------------------
DDN Infinite Memory Engine: no
Generic Unix FS: yes
IBM Spectrum Scale/GPFS: yes
Lustre: no
PVFS2/OrangeFS: no

